{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "class Node:\n",
    "    pass\n",
    "    \"\"\"结点\"\"\"\n",
    "    def __init__(self,feature_idx,sample_val,parent=None):\n",
    "        pass\n",
    "        \"\"\"\n",
    "            feature_val 记录保存在结点中的样本的值\n",
    "        \"\"\"\n",
    "        self.feature_idx = feature_idx\n",
    "        self.sample_val = sample_val\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class KNN:\n",
    "    pass\n",
    "    \"\"\"\n",
    "    k-nearest neighbor的kd树分类算法实现\n",
    "    kd树是存储k维空间的树结构，与k邻近算法中的k意义不同\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "        \"\"\"训练的过程其实就是构造kd树的过程\"\"\"\n",
    "        self.root = self._build_tree(X,0)\n",
    "\n",
    "    def _build_tree(self,X,deepth):\n",
    "        pass\n",
    "        \"\"\"\n",
    "        对于k维空间数据集\n",
    "        对深度为j的结点，选择 l = j(mod k) 坐标轴进行切分\"\"\"\n",
    "        n_samples,n_features = X.shape\n",
    "        if n_samples == 0:\n",
    "            return None\n",
    "        f_idx = deepth % n_features\n",
    "        if n_samples == 1:\n",
    "            return Node(feature_idx=f_idx, sample_val= X[0])\n",
    "\n",
    "        sort_idx = np.argsort(X[:,f_idx])\n",
    "        X = X[sort_idx]\n",
    "\n",
    "        median_idx = n_samples//2\n",
    "        #根据中位数划分左右子集\n",
    "        X_left = X[0:median_idx]\n",
    "        X_right = X[median_idx+1:n_samples]\n",
    "\n",
    "        #结点保存划分点的值和相应的标签\n",
    "        node = Node(feature_idx=f_idx,sample_val=X[median_idx])\n",
    "        node.left = self._build_tree(X_left,deepth+1)\n",
    "        node.right = self._build_tree(X_right,deepth+1)\n",
    "        return node\n",
    "\n",
    "\n",
    "    def preOrder(self,node):\n",
    "        if node == None:\n",
    "            return\n",
    "        print(node.sample_val)\n",
    "        self.preOrder(node.left)\n",
    "        self.preOrder(node.right)\n",
    "\n",
    "    def _visit(self,node,x):\n",
    "        pass\n",
    "        \"\"\"访问结点\"\"\"\n",
    "        if node != None:\n",
    "            dis = x[node.feature_idx] - node.sample_val[node.feature_idx]\n",
    "            if dis < 0:\n",
    "                self._visit(node.left,x)\n",
    "            else:\n",
    "                self._visit(node.right,x)\n",
    "\n",
    "            curr_dis = np.linalg.norm(x-node.sample_val,ord=2)\n",
    "            heapq.heappushpop(self.k_nearest_neighbor,(-curr_dis,node))\n",
    "            if -(self.k_nearest_neighbor[0][0]) > abs(dis):\n",
    "                self._visit(node.right if dis < 0 else node.left,x)\n",
    "\n",
    "    def _search_nearest_k_node(self,x,near_k=1):\n",
    "        pass\n",
    "        \"\"\"这里的k是寻找离X_test 最近的k个节点，采用的是欧式距离\"\"\"\n",
    "        #python的堆是最小堆，对于最大堆的支持很不友好\n",
    "        #所以转换一个思路，把距离取父值，值小的说明距离大\n",
    "        self.k_nearest_neighbor = [(-np.inf,None)]*near_k\n",
    "        self._visit(self.root,x)\n",
    "        self.k_nearest_neighbor = np.array(\n",
    "            [i[1].sample_val for i in heapq.nlargest(near_k,self.k_nearest_neighbor)]\n",
    "        )\n",
    "        return self.k_nearest_neighbor\n",
    "\n",
    "\n",
    "    def search(self,X_test,k=1):\n",
    "        pass\n",
    "        \"\"\"这里的k是寻找离X_test 最近的k个节点\"\"\"\n",
    "        res = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            res.append(self._search_nearest_k_node(X_test[i],near_k=k))\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查找结果： [array([[2, 3],\n",
      "       [5, 4]])]\n"
     ]
    }
   ],
   "source": [
    "arr =np.array([[2,3],[5,4],[9,6],[4,7],[8,1],[7,2]])\n",
    "\n",
    "knn = KNN()\n",
    "knn.fit(arr,np.arange(arr.shape[0],dtype=\"int\"))\n",
    "# print(\"======kd树前序遍历=========\")\n",
    "# knn.preOrder(knn.root)\n",
    "\n",
    "X_test = np.array([[2,4]])\n",
    "near = knn.search(X_test,k=2)\n",
    "\n",
    "print(\"查找结果：\",near)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "剩下的如果需要做分类则可以求结果的众数，回归则求结果的平均值即可（结点可以再存储一下标签值）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
